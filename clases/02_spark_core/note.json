{
  "paragraphs": [
    {
      "text": "print(s\"\"\"%html\n\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"$baseDir/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n\"\"\")\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611750_653962124",
      "id": "20171010-191319_1407757246",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n# Spark Core\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eSpark Core\u003c/h1\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611751_653577375",
      "id": "20171013-124120_1151991544",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Veremos conceptos básicos \n\n### aplicables a otras librerías:\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eVeremos conceptos básicos\u003c/h3\u003e\n\u003ch3\u003eaplicables a otras librerías:\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611752_651653630",
      "id": "20171013-125344_626244712",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n![](https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/02_spark_core/core_stack.png)\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/02_spark_core/core_stack.png\" /\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611752_651653630",
      "id": "20171013-125319_1987010321",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## ~.- Conceptos básicos\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003e~.- Conceptos básicos\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611753_651268882",
      "id": "20171013-125336_1933366904",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n### Driver\n\nToda aplicación Spark tiene un programa **driver**:\n\n* lanza las operaciones en el cluster,\n* contiene nuestro **programa**\n    - define datos distribuidos y les aplica operaciones.\n\n\u003e Zeppelin es un *programa driver* que de forma interactiva ejecuta las operaciones que queremos correr.\n\n### Executors\n\nEl driver maneja y envía tareas a **executors** en los nodos del cluster (o threads en modo local).\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eDriver\u003c/h3\u003e\n\u003cp\u003eToda aplicación Spark tiene un programa \u003cstrong\u003edriver\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003elanza las operaciones en el cluster,\u003c/li\u003e\n  \u003cli\u003econtiene nuestro \u003cstrong\u003eprograma\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003edefine datos distribuidos y les aplica operaciones.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n  \u003cp\u003eZeppelin es un \u003cem\u003eprograma driver\u003c/em\u003e que de forma interactiva ejecuta las operaciones que queremos correr.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3\u003eExecutors\u003c/h3\u003e\n\u003cp\u003eEl driver maneja y envía tareas a \u003cstrong\u003eexecutors\u003c/strong\u003e en los nodos del cluster (o threads en modo local).\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611753_651268882",
      "id": "20171013-130405_1538728027",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "println(s\"\"\"%html\n\u003cimg src\u003d\"$baseDir/01_intro_spark/driver_exec.png\" alt\u003d\"Drawing\" style\u003d\"width: 60%;\"/\u003e\n\"\"\")\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/01_intro_spark/driver_exec.png\" alt\u003d\"Drawing\" style\u003d\"width: 60%;\"/\u003e\n\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611754_652423128",
      "id": "20171013-123200_262582034",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### SparkContext\n\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eSparkContext\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611754_652423128",
      "id": "20171013-130511_1848331242",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n* Los programas en el driver se conectan al cluster Spark a través de un objeto `SparkContext`\n* Le dice a Spark como conectarce con el cluster (o a los distintos threads en modo local)\n    - (representa la conección al cluster) \n* En Zeppelin (y shell) está predefinida la variable `sc` de tipo `SparkContext`\n    - otros programas deben crearla con `new`\n\n![](https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/02_spark_core/cluster-overview.png)",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eLos programas en el driver se conectan al cluster Spark a través de un objeto \u003ccode\u003eSparkContext\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eLe dice a Spark como conectarce con el cluster (o a los distintos threads en modo local)\n    \u003cul\u003e\n      \u003cli\u003e(representa la conección al cluster)\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eEn Zeppelin (y shell) está predefinida la variable \u003ccode\u003esc\u003c/code\u003e de tipo \u003ccode\u003eSparkContext\u003c/code\u003e\n    \u003cul\u003e\n      \u003cli\u003eotros programas deben crearla con \u003ccode\u003enew\u003c/code\u003e\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/02_spark_core/cluster-overview.png\" /\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611754_652423128",
      "id": "20171013-160636_1142900877",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "sc.defaultParallelism\nsc.master\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611755_652038379",
      "id": "20171013-131916_230493933",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "sc.master",
      "text": "print(s\"\"\"%table\nmaster\\tdescripción\nlocal\\tSpark corre localmente con un solo worker (no paralelismo)\nlocal[K]\\tSpark corre localmente con K threads\nspark://HOST:PORT\\tse conecta a un cluster Spark\nmesos://HOST:PORT\\tse conecta a un cluster Mesos\nyarn\\tse conecta a un cluster Hadoop Yarn\n...\\t...\n\"\"\")\n\n\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "master\tdescripción\nlocal\tSpark corre localmente con un solo worker (no paralelismo)\nlocal[K]\tSpark corre localmente con K threads\nspark://HOST:PORT\tse conecta a un cluster Spark\nmesos://HOST:PORT\tse conecta a un cluster Mesos\nyarn\tse conecta a un cluster Hadoop Yarn\n...\t...\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611755_652038379",
      "id": "20171013-132159_1922125840",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n## ~.- Resilient Distributed Dataset (RDD)\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003e~.- Resilient Distributed Dataset (RDD)\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611756_650114635",
      "id": "20171013-130245_542901367",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n* **Contenedores** de objetos **inmutables**, distribuidos en el cluster (contiene los datos)\n\n* Creados con el SparkContext `sc`.\n    - al cargar datasets a Spark\n    - por transformaciones comunes (`map`, `filter`, ...) o binarias (`union`, `intersection`, ...).\n\n* Ante fallas se reconstruyen (resilencia).\n* **Importante**: todo lo que no derive del `SparkContext` corre solo en el **driver**.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003e\n  \u003cp\u003e\u003cstrong\u003eContenedores\u003c/strong\u003e de objetos \u003cstrong\u003einmutables\u003c/strong\u003e, distribuidos en el cluster (contiene los datos)\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\n    \u003cp\u003eCreados con el SparkContext \u003ccode\u003esc\u003c/code\u003e.\u003c/p\u003e\n    \u003cul\u003e\n      \u003cli\u003eal cargar datasets a Spark\u003c/li\u003e\n      \u003cli\u003epor transformaciones comunes (\u003ccode\u003emap\u003c/code\u003e, \u003ccode\u003efilter\u003c/code\u003e, \u0026hellip;) o binarias (\u003ccode\u003eunion\u003c/code\u003e, \u003ccode\u003eintersection\u003c/code\u003e, \u0026hellip;).\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eAnte fallas se reconstruyen (resilencia).\u003c/p\u003e\u003c/li\u003e\n  \u003cli\u003e\u003cstrong\u003eImportante\u003c/strong\u003e: todo lo que no derive del \u003ccode\u003eSparkContext\u003c/code\u003e corre solo en el \u003cstrong\u003edriver\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611756_650114635",
      "id": "20171013-161530_19251643",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejemplo log analysis",
      "text": "val inputRDD \u003d sc.textFile(\"./logs/\") // RDD de entrada\n\n// se crea un nuevo RDD:\nval errorRDD \u003d inputRDD.filter(line \u003d\u003e line.contains(\"ERROR\")) \n\n// se crea otro nuevo RDD\nval configRDD \u003d inputRDD.filter(line \u003d\u003e line.contains(\"config\")) \n\nval errOrConfRDD \u003d errorRDD.union(configRDD) \n\nerrOrConfRDD.collect\n    .foreach(println)\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611757_649729886",
      "id": "20171013-162323_997815285",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u003cimg src\u003d\"$baseDir/02_spark_core/log_linage.png\" alt\u003d\"Drawing\" style\u003d\"width: 70%;\"/\u003e\n\"\"\")\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/02_spark_core/log_linage.png\" alt\u003d\"Drawing\" style\u003d\"width: 70%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611757_649729886",
      "id": "20171013-164802_1824704614",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "{\nval uiHost \u003d sc.getConf.getOption(\"spark.driver.host\").getOrElse(\"localhost\")\nval uiPort \u003d sc.getConf.getOption(\"spark.ui.port\").getOrElse(\"4040\")\nprint(s\"\"\"\n%html\nEjecutar celda y ver en Spark UI tareas y grafo de operaciones\n\u003ca href\u003d\"http://$uiHost:$uiPort\"\u003ehttp://$uiHost(host):$uiPort(port)\u003c/a\u003e\n\"\"\")\n}\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n"
          },
          {
            "type": "HTML",
            "data": "Ejecutar celda y ver en Spark UI tareas y grafo de operaciones\n\u003ca href\u003d\"http://192.168.128.167:4040\"\u003ehttp://192.168.128.167(host):4040(port)\u003c/a\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611758_650884133",
      "id": "20171013-163432_1466279672",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Implementación",
      "text": "%md\n\n* El RDD se dividide en **particiones** (automático o explícito).\n* Se construye el **grafo de operaciones**.\n* Las operaciones de dividen en **tasks** (tareas).\n* A cada **partición** se le aplica una **task**.\n* Las tareas son ejecutadas por los executors en nodos o threads locales.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eEl RDD se dividide en \u003cstrong\u003eparticiones\u003c/strong\u003e (automático o explícito).\u003c/li\u003e\n  \u003cli\u003eSe construye el \u003cstrong\u003egrafo de operaciones\u003c/strong\u003e.\u003c/li\u003e\n  \u003cli\u003eLas operaciones de dividen en \u003cstrong\u003etasks\u003c/strong\u003e (tareas).\u003c/li\u003e\n  \u003cli\u003eA cada \u003cstrong\u003epartición\u003c/strong\u003e se le aplica una \u003cstrong\u003etask\u003c/strong\u003e.\u003c/li\u003e\n  \u003cli\u003eLas tareas son ejecutadas por los executors en nodos o threads locales.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611758_650884133",
      "id": "20171013-123100_1037283294",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\n\n* Cree una celda nueva y copie en ella el último programa sin las líneas 7 en adelante.\n* Observe en Spark UI las tareas ejecutadas.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cul\u003e\n  \u003cli\u003eCree una celda nueva y copie en ella el último programa sin las líneas 7 en adelante.\u003c/li\u003e\n  \u003cli\u003eObserve en Spark UI las tareas ejecutadas.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611758_650884133",
      "id": "20171013-165833_179635135",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## ~.- Evaluación Lazy\n\nEn Spark todas las **transformaciones** (`map`, `filter`, `union`, etc.) son evaluadas de forma **lazy**:\n\n* son acumuladas como *grafo de dependencias*\n* se ejecutan al momento de traer los datos al driver (`collect`, `take`, etc.)\n    - se llama a una **acción**.\n\nEsto permite:\n\n* hacer **optimizaciones**\n    - se computa solo lo que hace falta (tiene mucho sentido en Big Data)\n    - se hace un *pipeling* de transformaciones sin guardar resultados intermedios \n* recalcular las dependencias si hay algún fallo (resilencia)\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003e~.- Evaluación Lazy\u003c/h2\u003e\n\u003cp\u003eEn Spark todas las \u003cstrong\u003etransformaciones\u003c/strong\u003e (\u003ccode\u003emap\u003c/code\u003e, \u003ccode\u003efilter\u003c/code\u003e, \u003ccode\u003eunion\u003c/code\u003e, etc.) son evaluadas de forma \u003cstrong\u003elazy\u003c/strong\u003e:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eson acumuladas como \u003cem\u003egrafo de dependencias\u003c/em\u003e\u003c/li\u003e\n  \u003cli\u003ese ejecutan al momento de traer los datos al driver (\u003ccode\u003ecollect\u003c/code\u003e, \u003ccode\u003etake\u003c/code\u003e, etc.)\n    \u003cul\u003e\n      \u003cli\u003ese llama a una \u003cstrong\u003eacción\u003c/strong\u003e.\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eEsto permite:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ehacer \u003cstrong\u003eoptimizaciones\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003ese computa solo lo que hace falta (tiene mucho sentido en Big Data)\u003c/li\u003e\n      \u003cli\u003ese hace un \u003cem\u003epipeling\u003c/em\u003e de transformaciones sin guardar resultados intermedios\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003erecalcular las dependencias si hay algún fallo (resilencia)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611759_650499384",
      "id": "20171013-171238_638394270",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Logs análisis (solo una linea)",
      "text": "val inputRDD \u003d sc.textFile(\"./logs/\") // RDD de entrada\nval errorRDD \u003d inputRDD.filter(line \u003d\u003e line.contains(\"ERROR\")) // se crea un nuevo RDD\nval configRDD \u003d inputRDD.filter(line \u003d\u003e line.contains(\"config\")) // se crea un nuevo RDD\n\nval errOrConfRDD \u003d errorRDD.union(configRDD) \n\nerrOrConfRDD.take(2) // en ves de traer todo\n    .foreach(println)\n// Compara con primer programa en Spark UI\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611760_660887604",
      "id": "20171013-172118_1147412885",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\n\nComplete los `...` en el siguiente programa para contar la cantidad de veces que aparece la letra \u0027c\u0027 en los archivos en `./logs/`.\n\n#### Ayuda\n\n\n* Se puede usar el método `.filter` (ya visto en ejemplos anteriores) para crear un RDD solo con la letra C.\n* El método `count` de RDD cuenta la cantidad de elementos.\n* La letra \u0027c\u0027 se escribe `\u0027c\u0027` en Scala.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eComplete los \u003ccode\u003e...\u003c/code\u003e en el siguiente programa para contar la cantidad de veces que aparece la letra \u0026lsquo;c\u0026rsquo; en los archivos en \u003ccode\u003e./logs/\u003c/code\u003e.\u003c/p\u003e\n\u003ch4\u003eAyuda\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003eSe puede usar el método \u003ccode\u003e.filter\u003c/code\u003e (ya visto en ejemplos anteriores) para crear un RDD solo con la letra C.\u003c/li\u003e\n  \u003cli\u003eEl método \u003ccode\u003ecount\u003c/code\u003e de RDD cuenta la cantidad de elementos.\u003c/li\u003e\n  \u003cli\u003eLa letra \u0026lsquo;c\u0026rsquo; se escribe \u003ccode\u003e\u0026#39;c\u0026#39;\u003c/code\u003e en Scala.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611760_660887604",
      "id": "20171013-174042_1672649057",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val linesRDD \u003d sc.textFile(\"./logs/\")\n\nval charsRDD \u003d linesRDD\n                .flatMap(l \u003d\u003e l)\n\nval onlyCRDD \u003d charsRDD.\n                    ...(c \u003d\u003e ... \u003d\u003d ...)\n\nonlyCRDD.count\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611761_660502855",
      "id": "20171013-175507_696892344",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## ~.- Persistencia\n\nSpark **recomputa** el grafo de dependencias cuando se llama una **acción**:",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003e~.- Persistencia\u003c/h2\u003e\n\u003cp\u003eSpark \u003cstrong\u003erecomputa\u003c/strong\u003e el grafo de dependencias cuando se llama una \u003cstrong\u003eacción\u003c/strong\u003e:\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611761_660502855",
      "id": "20171016-174448_43219511",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val input \u003d sc.parallelize(1 to 30) // Se crea el arreglo [1,...,30] y se lo convierte en RDD \nval result \u003d input.map(x \u003d\u003e x*x)\n\nprintln(\"La media es \" + result.mean()) // computa el map\n\nresult.collect()\n     .foreach(println) // recomputa el map",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611762_661657102",
      "id": "20171016-174929_1389420364",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "{\nval uiHost \u003d sc.getConf.getOption(\"spark.driver.host\").getOrElse(\"localhost\")\nval uiPort \u003d sc.getConf.getOption(\"spark.ui.port\").getOrElse(\"4040\")\nprint(s\"\"\"\n%html\n(ver resultado en Spark UI\n\u003ca href\u003d\"http://$uiHost:$uiPort\"\u003ehttp://$uiHost(host):$uiPort(port)\u003c/a\u003e)\n\u003cbr\u003e\n\u003cbr\u003e\nPara evitarlo Spark puede cachear los datos:\n\"\"\")\n}",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n"
          },
          {
            "type": "HTML",
            "data": "(ver resultado en Spark UI\n\u003ca href\u003d\"http://192.168.1.201:4040\"\u003ehttp://192.168.1.201(host):4040(port)\u003c/a\u003e)\n\u003cbr\u003e\n\u003cbr\u003e\nPara evitarlo Spark puede cachear los datos:\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611762_661657102",
      "id": "20171016-175252_2114983095",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val input \u003d sc.parallelize(1 to 30)\nval result \u003d input.map(x \u003d\u003e x*x)\n                .setName(\"cuadrados2\").cache() // cache de datis\n\nprintln(\"La media es \" + result.mean()) // computa el map\n\nresult.collect()\n     .foreach(println) // recomputa el map\n\n//result.unpersist()",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611763_661272353",
      "id": "20171016-175416_1988336119",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "{\nval uiHost \u003d sc.getConf.getOption(\"spark.driver.host\").getOrElse(\"localhost\")\nval uiPort \u003d sc.getConf.getOption(\"spark.ui.port\").getOrElse(\"4040\")\nprint(s\"\"\"\n%html\nVer resultado en Spark UI\n\u003ca href\u003d\"http://$uiHost:$uiPort/storage\"\u003ehttp://$uiHost(host):$uiPort(port)/storage\u003c/a\u003e\n\u003cbr\u003e\nObservar tambien green dots en Dag Visualization.\n\"\"\")\n}",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n"
          },
          {
            "type": "HTML",
            "data": "Ver resultado en Spark UI\n\u003ca href\u003d\"http://192.168.1.201:4040/storage\"\u003ehttp://192.168.1.201(host):4040(port)/storage\u003c/a\u003e\n\u003cbr\u003e\nObservar tambien green dots en Dag Visualization.\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611764_659348608",
      "id": "20171016-180034_191267646",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nModifique el siguiente programa para que cuente la cantidad de lineas que comienzan con la palabra `INFO`, `WARN` y `ERROR`.\n\nHaga cache de los RDD para hacer el programa más eficiente. \n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eModifique el siguiente programa para que cuente la cantidad de lineas que comienzan con la palabra \u003ccode\u003eINFO\u003c/code\u003e, \u003ccode\u003eWARN\u003c/code\u003e y \u003ccode\u003eERROR\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eHaga cache de los RDD para hacer el programa más eficiente.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611765_658963860",
      "id": "20171016-193030_671507369",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val linesRDD \u003d sc.textFile(\"./logs/\") // RDD de entrada\n\nval linesTrim \u003d inputRDD.map(l \u003d\u003e l.trim) // Borro espacios en borde\n\nval linesInfo \u003d linesTrim.filter(l \u003d\u003e l.startsWith(\"INFO\"))\n\nval linesWarn \u003d // Completar\n\nval linesError \u003d // Completar\n\nprintln(\"Cantidad de lineas INFO: \" + linesInfo.count )\n\nprintln(\"Cantidad de lineas WARN: \" + ... ) //Completar\n\nprintln(\"Cantidad de lineas ERROR: \" + ... )  //Completar\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611765_658963860",
      "id": "20171016-193608_2127680777",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nEl archivo en `~/diplodatos_bigdata/ds/flights.csv` contiene información de vuelos realizados en 2008 (solo 100.000), uno por línea.\n\nLos datos estan separados por coma y la columna 22 tiene un `1` si el vuelo fue cancelado. Además si el vuelo fue redirigido se indica con \u00271\u0027 en la columna 24.\n\nCompletar el siguiente programa que devuelve el porcentaje de vuelos cancelados y el porcentaje de redirigidos.\n\nUtilizar cache si lo cree conveniente.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eEl archivo en \u003ccode\u003e~/diplodatos_bigdata/ds/flights.csv\u003c/code\u003e contiene información de vuelos realizados en 2008 (solo 100.000), uno por línea.\u003c/p\u003e\n\u003cp\u003eLos datos estan separados por coma y la columna 22 tiene un \u003ccode\u003e1\u003c/code\u003e si el vuelo fue cancelado. Además si el vuelo fue redirigido se indica con \u0026lsquo;1\u0026rsquo; en la columna 24.\u003c/p\u003e\n\u003cp\u003eCompletar el siguiente programa que devuelve el porcentaje de vuelos cancelados y el porcentaje de redirigidos.\u003c/p\u003e\n\u003cp\u003eUtilizar cache si lo cree conveniente.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611765_658963860",
      "id": "20171016-224717_280061616",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val input \u003d sc.textFile(\".../diplodatos_bigdata/ds/flights.csv\") // Completar el path\n\nval nTotal \u003d input.count - 1 // la primer fila tiene el nombre de las columnas\n\nval parsed \u003d input.map(l \u003d\u003e l.split(\",\"))\n\nval cancel \u003d parsed.filter(l \u003d\u003e l(21) \u003d\u003d ...) // Completar\n\nval redir \u003d ... //completar\n\nval nCancel \u003d cancel.count\nval nRedir \u003d redir.count\n\nprintln(\"% cancelados \u003d \" + nCancel.toDouble *100 / nTotal)\nprintln(\"% redireccionados \u003d \" + ... ) // Completar\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611766_660118106",
      "id": "20171016-230006_1932654725",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nLa columna 14 del mismo archivo tiene el tiempo del vuelo en minutos. Calcular el máximo.\n\n#### Ayuda\n\n* Busque en la documentacion de la [API RDD](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD) una acción para calcular el máximo.\n* Ojo que puede haber valores no definidos.\n",
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eLa columna 14 del mismo archivo tiene el tiempo del vuelo en minutos. Calcular el máximo.\u003c/p\u003e\n\u003ch4\u003eAyuda\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003eBusque en la documentacion de la \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.rdd.RDD\"\u003eAPI RDD\u003c/a\u003e una acción para calcular el máximo.\u003c/li\u003e\n  \u003cli\u003eOjo que puede haber valores no definidos.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611767_659733357",
      "id": "20171016-232257_285172371",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "FIN",
      "text": "val baseDir\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\"\n\nz.put(\"baseDir\", baseDir)\nprint(\"\"\"%html\n\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n\"\"\")",
      "dateUpdated": "Oct 11, 2018 9:53:51 PM",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "baseDir: String \u003d https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\n"
          },
          {
            "type": "HTML",
            "data": "\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539305611767_659733357",
      "id": "20171010-191336_1667301043",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "dateUpdated": "Oct 11, 2018 9:53:31 PM",
      "config": {},
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539305611770_658579111",
      "id": "20171010-192055_1187380897",
      "dateCreated": "Oct 11, 2018 9:53:31 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Clase 02 - Spark Core",
  "id": "2DUWRZ4FJ",
  "angularObjects": {
    "2DVCPKERU:shared_process": [],
    "2DRH5MGD2:shared_process": [],
    "2DT8RGM5K:shared_process": [],
    "2DTBNGED4:shared_process": [],
    "2DUJTWGBK:shared_process": [],
    "2DVDPKT5E:shared_process": [],
    "2DTHT6XEM:shared_process": [],
    "2DSR5ZQRN:shared_process": [],
    "2DUUQHMED:shared_process": [],
    "2DUYR3928:shared_process": [],
    "2DU693TAM:shared_process": [],
    "2DTUS9FCK:shared_process": [],
    "2DSAF8SZS:shared_process": [],
    "2DSYWZ69A:shared_process": [],
    "2DTR3QF32:shared_process": [],
    "2DU2RAXU9:shared_process": [],
    "2DSG68MMD:shared_process": [],
    "2DTTN7EC4:shared_process": [],
    "2DV1379NW:shared_process": []
  },
  "config": {},
  "info": {}
}