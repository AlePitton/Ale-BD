{
  "paragraphs": [
    {
      "text": "print(s\"\"\"%html\n\u003ccenter\u003e\n    \u003ch1\u003eCurso Big Data Vates 2017\u003c/h1\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch2 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h2\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"$baseDir/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 19, 2017 10:42:51 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ccenter\u003e\n    \u003ch1\u003eCurso Big Data Vates 2017\u003c/h1\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch2 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h2\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"https://bytebucket.org/bigdata_famaf/curso_vates/raw/HEAD/clases/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761484_1738072860",
      "id": "20161011-125025_834797080",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 19, 2017 10:42:20 AM",
      "dateFinished": "Oct 19, 2017 10:42:20 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "%md\n### Antes de comenzar\n#### En máquina virtual\n1. Lanzar terminal\n1. Actualizar repo:\n```sh\ncd curso_vates\ngit pull\n```\n1. Lanzar [Zeppelin](http://zeppelin.apache.org/):\n```sh\ncd\ncd spark/zeppelin-0.7.3-bin-all\n./bin/zeppelin-daemon.sh start\n```\n1. En navegador abrir [http://localhost:8080](http://localhost:8080)\n1. Seleccionar `Import note`\n1. Elegir json en `/home/guest/curso_vates/clases/03_sql/note.json`\n2. Seleccionar `Clase 03 - SQL`\n\n \n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 4:32:34 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "title": false,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eAntes de comenzar\u003c/h3\u003e\n\u003ch4\u003eEn máquina virtual\u003c/h4\u003e\n\u003col\u003e\n  \u003cli\u003eLanzar terminal\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eActualizar repo:\u003c/p\u003e\n  \u003cpre\u003e\u003ccode class\u003d\"sh\"\u003ecd curso_vates\ngit pull\n\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eLanzar \u003ca href\u003d\"http://zeppelin.apache.org/\"\u003eZeppelin\u003c/a\u003e:\u003c/p\u003e\n  \u003cpre\u003e\u003ccode class\u003d\"sh\"\u003ecd\ncd spark/zeppelin-0.7.3-bin-all\n./bin/zeppelin-daemon.sh start\n\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n  \u003cli\u003eEn navegador abrir \u003ca href\u003d\"http://localhost:8080\"\u003ehttp://localhost:8080\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eSeleccionar \u003ccode\u003eImport note\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eElegir json en \u003ccode\u003e/home/guest/curso_vates/clases/03_sql/note.json\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eSeleccionar \u003ccode\u003eClase 03 - SQL\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508872734942_-1386283918",
      "id": "20171024-161854_528178880",
      "dateCreated": "Oct 24, 2017 4:18:54 PM",
      "dateStarted": "Oct 24, 2017 4:32:18 PM",
      "dateFinished": "Oct 24, 2017 4:32:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Datasets/Dataframes\n\n* Spark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente **Spark SQL**.\n* Sus interfaces son SQL y Dataset/Dataframe API (programática, parecida a [Python Panda dataframes](http://pandas.pydata.org/pandas-docs/stable/dsintro.html)).\n\u003cbr\u003e\n\n    ```scala\n      type DataFrame \u003d Dataset[Row]\n    ```\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:05:53 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eDatasets/Dataframes\u003c/h1\u003e\n\u003cul\u003e\n  \u003cli\u003eSpark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente \u003cstrong\u003eSpark SQL\u003c/strong\u003e.\u003c/li\u003e\n  \u003cli\u003eSus interfaces son SQL y Dataset/Dataframe API (programática, parecida a \u003ca href\u003d\"http://pandas.pydata.org/pandas-docs/stable/dsintro.html\"\u003ePython Panda dataframes\u003c/a\u003e).\u003cbr/\u003e\u003cbr\u003e\n    \u003cpre\u003e\u003ccode class\u003d\"scala\"\u003e  type DataFrame \u003d Dataset[Row]\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761488_1749230578",
      "id": "20161011-125142_1705237118",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 23, 2017 5:21:28 PM",
      "dateFinished": "Oct 23, 2017 5:21:28 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 19, 2017 10:48:55 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://bytebucket.org/bigdata_famaf/curso_vates/raw/HEAD/clases/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761492_1747691583",
      "id": "20161011-132101_236091967",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 19, 2017 10:48:46 AM",
      "dateFinished": "Oct 19, 2017 10:48:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "API 2.x.x unificada",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 19, 2017 10:52:03 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://bytebucket.org/bigdata_famaf/curso_vates/raw/HEAD/clases/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761498_1746922085",
      "id": "20161011-134614_1124280099",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 19, 2017 10:51:57 AM",
      "dateFinished": "Oct 19, 2017 10:51:57 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### SparkSession\n\n* Para acceder al cluster desde la API se utiliza `SparkSession`.\n* El `SparkContext` deriva de él.\n\n```scala\nimport org.apache.spark.sql.SparkSession\n\nval spark \u003d SparkSession\n  .builder()\n  .appName(\"Spark ejemplo\")\n  .config(\"spark.some.config.option\", \"algun-valor\")\n  .getOrCreate()\n\nval sc \u003d spark.sparkContext\n\n// Para conversion implícita, por ej entre RDD a DataFrames\nimport spark.implicits._\n```\n\n* En Zeppelin ya están predefinidos: \n  - `SparkSession` objeto `spark` \n  - `SparkContext` objeto `sc`\n\n(más información en [How to use SparkSession in Apache Spark 2.0](https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html) y [Apache Spark 2.0 Examples](https://docs.cloud.databricks.com/docs/latest/sample_applications/04%20Apache%20Spark%202.0%20Examples/01%20SparkSession.html))\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:50:39 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eSparkSession\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003ePara acceder al cluster desde la API se utiliza \u003ccode\u003eSparkSession\u003c/code\u003e.\u003c/li\u003e\n  \u003cli\u003eEl \u003ccode\u003eSparkContext\u003c/code\u003e deriva de él.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eimport org.apache.spark.sql.SparkSession\n\nval spark \u003d SparkSession\n  .builder()\n  .appName(\u0026quot;Spark ejemplo\u0026quot;)\n  .config(\u0026quot;spark.some.config.option\u0026quot;, \u0026quot;algun-valor\u0026quot;)\n  .getOrCreate()\n\nval sc \u003d spark.sparkContext\n\n// Para conversion implícita, por ej entre RDD a DataFrames\nimport spark.implicits._\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n  \u003cli\u003eEn Zeppelin ya están predefinidos:\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkSession\u003c/code\u003e objeto \u003ccode\u003espark\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkContext\u003c/code\u003e objeto \u003ccode\u003esc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(más información en \u003ca href\u003d\"https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html\"\u003eHow to use SparkSession in Apache Spark 2.0\u003c/a\u003e y \u003ca href\u003d\"https://docs.cloud.databricks.com/docs/latest/sample_applications/04%20Apache%20Spark%202.0%20Examples/01%20SparkSession.html\"\u003eApache Spark 2.0 Examples\u003c/a\u003e)\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761500_1744613592",
      "id": "20161011-174856_51715674",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 19, 2017 11:00:53 AM",
      "dateFinished": "Oct 19, 2017 11:00:53 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Lectura\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:10:50 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "editorHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eLectura\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508506108111_-129380035",
      "id": "20171020-102828_1480663464",
      "dateCreated": "Oct 20, 2017 10:28:28 AM",
      "dateStarted": "Oct 20, 2017 10:29:02 AM",
      "dateFinished": "Oct 20, 2017 10:29:02 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n#### Formatos:\n\n* json\n* csv\n* parquet\n* orc\n* libsvm\n* text\n* ...\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:11:00 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFormatos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003ejson\u003c/li\u003e\n  \u003cli\u003ecsv\u003c/li\u003e\n  \u003cli\u003eparquet\u003c/li\u003e\n  \u003cli\u003eorc\u003c/li\u003e\n  \u003cli\u003elibsvm\u003c/li\u003e\n  \u003cli\u003etext\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508441481680_-117760653",
      "id": "20171019-163121_1592075078",
      "dateCreated": "Oct 19, 2017 4:31:21 PM",
      "dateStarted": "Oct 20, 2017 4:52:24 PM",
      "dateFinished": "Oct 20, 2017 4:52:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Fuentes de datos:\n\n* Archivos en fs local o distribuid (ej hdfs)\n* jdbc (posgress, oracle, mysql,...)\n* Apache Hive (se usa execution backend Spark en ves de MR)\n* Amazon Redshift, S3\n* Azure Storage Services\n* Cassandra\n* MongoDB\n* Neo4j\n* ...",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:11:08 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFuentes de datos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003eArchivos en fs local o distribuid (ej hdfs)\u003c/li\u003e\n  \u003cli\u003ejdbc (posgress, oracle, mysql,\u0026hellip;)\u003c/li\u003e\n  \u003cli\u003eApache Hive (se usa execution backend Spark en ves de MR)\u003c/li\u003e\n  \u003cli\u003eAmazon Redshift, S3\u003c/li\u003e\n  \u003cli\u003eAzure Storage Services\u003c/li\u003e\n  \u003cli\u003eCassandra\u003c/li\u003e\n  \u003cli\u003eMongoDB\u003c/li\u003e\n  \u003cli\u003eNeo4j\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508506163491_-540414454",
      "id": "20171020-102923_1888981134",
      "dateCreated": "Oct 20, 2017 10:29:23 AM",
      "dateStarted": "Oct 23, 2017 10:05:46 AM",
      "dateFinished": "Oct 23, 2017 10:05:46 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Ejemplo\n\n#### Tabla de perfiles [last.fm](last.fm)\n\nFormato:\n\n    id \\t gender (\u0027m\u0027|\u0027f\u0027|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:11:17 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEjemplo\u003c/h3\u003e\n\u003ch4\u003eTabla de perfiles \u003ca href\u003d\"last.fm\"\u003elast.fm\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eFormato:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eid \\t gender (\u0026#39;m\u0026#39;|\u0026#39;f\u0026#39;|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508529628956_822306277",
      "id": "20171020-170028_1956391103",
      "dateCreated": "Oct 20, 2017 5:00:28 PM",
      "dateStarted": "Oct 20, 2017 5:14:50 PM",
      "dateFinished": "Oct 20, 2017 5:14:50 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura",
      "text": "val profiles \u003d spark.read.format(\"csv\")\n                .option(\"delimiter\", \"\\\\t\")\n                .option(\"header\", \"true\")\n                .option(\"inferSchema\", \"true\")\n                .load(\"/home/guest/curso_vates/ds/userid-profile.tsv\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 11:56:12 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508440171003_-2063902144",
      "id": "20171019-160931_1102056402",
      "dateCreated": "Oct 19, 2017 4:09:31 PM",
      "dateStarted": "Oct 23, 2017 9:05:20 AM",
      "dateFinished": "Oct 23, 2017 9:05:21 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Esquema",
      "text": "profiles.printSchema\n\nprofiles.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:12:04 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508529328594_488868543",
      "id": "20171020-165528_926197483",
      "dateCreated": "Oct 20, 2017 4:55:28 PM",
      "dateStarted": "Oct 20, 2017 5:04:06 PM",
      "dateFinished": "Oct 20, 2017 5:04:07 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Query SQL plano",
      "text": "profiles.createOrReplaceTempView(\"users\")\n\n//Cantidad de usuarios por país\nval nUsr4Ctry \u003d spark.sql(\"SELECT country, count(*) AS cantidad FROM users GROUP BY country ORDER BY cantidad DESC\")\n\nnUsr4Ctry.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 4:57:29 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508539804319_1166565048",
      "id": "20171020-195004_405222821",
      "dateCreated": "Oct 20, 2017 7:50:04 PM",
      "dateStarted": "Oct 23, 2017 11:53:46 AM",
      "dateFinished": "Oct 23, 2017 11:53:48 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Query SQL programático",
      "text": "val nUsr4Ctry2 \u003d profiles\n                .groupBy($\"country\").agg(count($\"*\").as(\"cantidad\"))\n                .orderBy($\"cantidad\".desc)\n\nnUsr4Ctry2.show\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 11:52:14 AM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508533936166_-220833432",
      "id": "20171020-181216_461915575",
      "dateCreated": "Oct 20, 2017 6:12:16 PM",
      "dateStarted": "Oct 23, 2017 9:21:06 AM",
      "dateFinished": "Oct 23, 2017 9:21:07 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nCalcular en un Dataframe la cantidad de usuarios por pais desagregando por sexo.\n\nSe puede usar SQL plano o programático.",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:12:31 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCalcular en un Dataframe la cantidad de usuarios por pais desagregando por sexo.\u003c/p\u003e\n\u003cp\u003eSe puede usar SQL plano o programático.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508769892643_-1262574416",
      "id": "20171023-114452_748688701",
      "dateCreated": "Oct 23, 2017 11:44:52 AM",
      "dateStarted": "Oct 23, 2017 4:36:33 PM",
      "dateFinished": "Oct 23, 2017 4:36:33 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:26:54 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508851600962_-2029104767",
      "id": "20171024-102640_808955464",
      "dateCreated": "Oct 24, 2017 10:26:40 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura desde JDBC",
      "text": "%md\n```scala\nval opts \u003d Map(\n  \"url\" -\u003e \"jdbc:postgresql:sparkdb\",\n  \"dbtable\" -\u003e \"projects\")\nval df \u003d spark.\n  read.\n  format(\"jdbc\").\n  options(opts).\n  load\n```\nMás información en:\n\n* [Mastering Apache Spark](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/exercises/spark-exercise-dataframe-jdbc-postgresql.html).\n* [Databricks](https://docs.databricks.com/spark/latest/data-sources/sql-databases.html).\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:12:48 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eval opts \u003d Map(\n  \u0026quot;url\u0026quot; -\u0026gt; \u0026quot;jdbc:postgresql:sparkdb\u0026quot;,\n  \u0026quot;dbtable\u0026quot; -\u0026gt; \u0026quot;projects\u0026quot;)\nval df \u003d spark.\n  read.\n  format(\u0026quot;jdbc\u0026quot;).\n  options(opts).\n  load\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/exercises/spark-exercise-dataframe-jdbc-postgresql.html\"\u003eMastering Apache Spark\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://docs.databricks.com/spark/latest/data-sources/sql-databases.html\"\u003eDatabricks\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508761615731_1644022997",
      "id": "20171023-092655_178501000",
      "dateCreated": "Oct 23, 2017 9:26:55 AM",
      "dateStarted": "Oct 23, 2017 9:12:41 PM",
      "dateFinished": "Oct 23, 2017 9:12:41 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura desde HIVE",
      "text": "%md\n```scala\nval spark \u003d SparkSession\n  .builder()\n  .appName(\"Spark Hive Example\")\n  .config(\"spark.sql.warehouse.dir\", warehouseLocation)\n  .enableHiveSupport()\n  .getOrCreate()\n  \nval sqlDF \u003d spark.sql(\"SELECT key, value FROM src WHERE key \u003c 10 ORDER BY key\")\n```\nMás información en:\n\n* [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables).\n* [Mastering Spark](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-hive-integration.html).\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:12:57 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eval spark \u003d SparkSession\n  .builder()\n  .appName(\u0026quot;Spark Hive Example\u0026quot;)\n  .config(\u0026quot;spark.sql.warehouse.dir\u0026quot;, warehouseLocation)\n  .enableHiveSupport()\n  .getOrCreate()\n  \nval sqlDF \u003d spark.sql(\u0026quot;SELECT key, value FROM src WHERE key \u0026lt; 10 ORDER BY key\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables\"\u003eSpark SQL\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/spark-sql-hive-integration.html\"\u003eMastering Spark\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508762221735_-663491301",
      "id": "20171023-093701_2112740736",
      "dateCreated": "Oct 23, 2017 9:37:01 AM",
      "dateStarted": "Oct 23, 2017 11:44:37 AM",
      "dateFinished": "Oct 23, 2017 11:44:37 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Escritura",
      "user": "anonymous",
      "dateUpdated": "Oct 25, 2017 10:28:35 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEscritura\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508770539354_-464068851",
      "id": "20171023-115539_2069683705",
      "dateCreated": "Oct 23, 2017 11:55:39 AM",
      "dateStarted": "Oct 23, 2017 9:51:08 PM",
      "dateFinished": "Oct 23, 2017 9:51:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "SQL",
      "text": "spark.sql(\"create table mytable as select * from users\");\n// Simula Hive Dat Warehouse local\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:13:39 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508770517607_-2039276821",
      "id": "20171023-115517_1163412651",
      "dateCreated": "Oct 23, 2017 11:55:17 AM",
      "dateStarted": "Oct 23, 2017 4:51:52 PM",
      "dateFinished": "Oct 23, 2017 4:51:55 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Dataframe",
      "text": "import org.apache.spark.sql.SaveMode\n\nprofiles.write.mode(SaveMode.Overwrite).save(\"./profiles.parquet\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 25, 2017 10:28:27 AM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508770638076_717784536",
      "id": "20171023-115718_1445962443",
      "dateCreated": "Oct 23, 2017 11:57:18 AM",
      "dateStarted": "Oct 23, 2017 4:53:35 PM",
      "dateFinished": "Oct 23, 2017 4:53:36 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls -ld ./spark-warehouse\nls -l ./spark-warehouse\n\nls -ld ./*.parquet",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 4:54:20 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508788358314_1161411014",
      "id": "20171023-165238_672281439",
      "dateCreated": "Oct 23, 2017 4:52:38 PM",
      "dateStarted": "Oct 23, 2017 4:54:07 PM",
      "dateFinished": "Oct 23, 2017 4:54:08 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nCalcule la edad promedio por género y guarde el resultado como tabla o como archivo parquet.\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:14:20 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "title": true,
        "editorHide": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCalcule la edad promedio por género y guarde el resultado como tabla o como archivo parquet.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508788194111_-940935242",
      "id": "20171023-164954_326955331",
      "dateCreated": "Oct 23, 2017 4:49:54 PM",
      "dateStarted": "Oct 23, 2017 4:55:13 PM",
      "dateFinished": "Oct 23, 2017 4:55:13 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:26:32 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508851585400_1447086222",
      "id": "20171024-102625_2088080876",
      "dateCreated": "Oct 24, 2017 10:26:25 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nMas información en \n* [API Dataset](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)\n* [Column Class](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column)\n* [Function Reference](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$)\n* [Doc Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n* [API DataFrameWriter](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameWriter)",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:22:28 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eMas información en\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\"\u003eAPI Dataset\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column\"\u003eColumn Class\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\"\u003eFunction Reference\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/sql-programming-guide.html\"\u003eDoc Spark SQL\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameWriter\"\u003eAPI DataFrameWriter\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761530_1734610120",
      "id": "20161012-103356_1938807399",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 23, 2017 9:22:20 PM",
      "dateFinished": "Oct 23, 2017 9:22:20 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Eficiencia\n\nLos RDD tienen el overhead de la *serialización* (aunque use *Kryo*):\n* cuando los objetos se transfieren (red) y guardan (disco)\n* overhead de garbage collector de la JVM\n\nLos Datasets solucionan estos problemas:\n* Serializa a binario usando **encoders**\n    - parte del proyecto Tungsten\n    - permite operaciones sin deserializar\n    - corre *off-heap* (sin garbage collection)\n    - código para serialización generado en forma dinámica\n* Con la información de la estructura (*schema*) Spark hace optimizaciones.\n    - Usa *Catalyst optimizer*.\n    - Transfiere solo columnas usadas, no objetos enteros (relational query plan).\n",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ch3\u003eEficiencia\u003c/h3\u003e\n\u003cp\u003eLos RDD tienen el overhead de la \u003cem\u003eserialización\u003c/em\u003e (aunque use \u003cem\u003eKryo\u003c/em\u003e):\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003ecuando los objetos se transfieren (red) y guardan (disco)\u003c/li\u003e\n\u003cli\u003eoverhead de garbage collector de la JVM\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLos Datasets solucionan estos problemas:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSerializa a binario usando \u003cstrong\u003eencoders\u003c/strong\u003e\u003cul\u003e\n\u003cli\u003eparte del proyecto Tungsten\u003c/li\u003e\n\u003cli\u003epermite operaciones sin deserializar\u003c/li\u003e\n\u003cli\u003ecorre \u003cem\u003eoff-heap\u003c/em\u003e (sin garbage collection)\u003c/li\u003e\n\u003cli\u003ecódigo para serialización generado en forma dinámica\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eCon la información de la estructura (\u003cem\u003eschema\u003c/em\u003e) Spark hace optimizaciones.\u003cul\u003e\n\u003cli\u003eUsa \u003cem\u003eCatalyst optimizer\u003c/em\u003e.\u003c/li\u003e\n\u003cli\u003eTransfiere solo columnas usadas, no objetos enteros (relational query plan).\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761507_1731147380",
      "id": "20161011-174737_215333010",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "WordCount con RDD",
      "text": "val linesRDD \u003d sc.textFile(\"README.md\")\n\nval wordsRDD \u003d linesRDD\n                .flatMap(l \u003d\u003e l.split(\" \"))\n                .filter(w \u003d\u003e ! w.isEmpty)\n//MapReduce:\nval wordCountRDD \u003d wordsRDD.map(w \u003d\u003e (w,1))\n                .reduceByKey((nx,ny) \u003d\u003e nx+ny)\n\nval resultRDD \u003d wordCountRDD\n                .sortBy((p \u003d\u003e p._2), ascending \u003d false)\n                // ordena por cantidad\n\nprintln(\"Resultado:\")\n\nresultRDD.collect() // traigo resultados\n      .take(3)\n      .foreach(p \u003d\u003e println(p))",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:20:38 AM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508419761509_1728838887",
      "id": "20161011-173655_294413553",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 24, 2017 10:16:59 AM",
      "dateFinished": "Oct 24, 2017 10:17:01 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "WordCount con Dataset",
      "text": "val linesDS \u003d spark.read.text(\"README.md\").as[String]\n\nval wordsDS \u003d linesDS\n                .flatMap(l \u003d\u003e l.split(\" \"))\n                .filter(w \u003d\u003e ! w.isEmpty)\n\nval wordCountDS \u003d wordsDS\n                .groupBy($\"value\").count\n\nval resultDS \u003d wordCountDS\n                .orderBy($\"count\".desc)\n                // ordena por cantidad\n\nprintln(\"Resultado:\")\n\nresultDS.show(3)\n\nprintln(\"El schema de words es:\")\nwordsDS.printSchema()",
      "user": "anonymous",
      "dateUpdated": "Oct 25, 2017 10:13:25 AM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508419761510_1729993133",
      "id": "20161011-190925_989390669",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 24, 2017 10:20:39 AM",
      "dateFinished": "Oct 24, 2017 10:20:42 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/08_datasets_dataframes/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761512_1727684640",
      "id": "20161011-201107_202795512",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/08_datasets_dataframes/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761513_1727299891",
      "id": "20161011-201419_1048673058",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Tungsten en acción",
      "text": "val ints \u003d 1 to math.pow(10, 6).toInt\nval intsRDD \u003d sc.parallelize(ints).setName(\"intsRDD\").cache\n\n// Fuerzo evaluacion\nintsRDD.count\n\n// Ver sparkui storage. Descomentar proximas lineas y ver de nuevo\n\n//val intsDF \u003d ints.toDF.cache\n\n//intsDF.count\n",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 5:15:59 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508419761517_1725760896",
      "id": "20161017-104100_1861019655",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 23, 2017 5:15:59 PM",
      "dateFinished": "Oct 23, 2017 5:16:01 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "{\nval uiHost \u003d sc.getConf.getOption(\"spark.driver.host\").getOrElse(\"localhost\")\nval uiPort \u003d sc.getConf.getOption(\"spark.ui.port\").getOrElse(\"4040\")\nprint(s\"\"\"\n%html\n\u003cbr\u003e\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://$uiHost:$uiPort/storage\"\u003ehttp://$uiHost(host):$uiPort(port)/storage\u003c/a\u003e\n\"\"\")\n}",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 5:27:24 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n"
          },
          {
            "type": "HTML",
            "data": "\u003cbr\u003e\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://192.168.1.200:4040/storage\"\u003ehttp://192.168.1.200(host):4040(port)/storage\u003c/a\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761518_1726915142",
      "id": "20161017-104452_771251326",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 23, 2017 5:07:26 PM",
      "dateFinished": "Oct 23, 2017 5:07:26 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejemplo",
      "text": "val df \u003d spark.read.json(\"/home/guest/curso_vates/ds/people.json\")\n\n// Displays the content of the DataFrame to stdout\ndf.show()\n\n// Selecciona todo incrementando la edad\ndf.select($\"name\", $\"age\" + 1).show()\n\n// Selecciona personas con mas de 21 años\ndf.filter($\"age\" \u003e 21).show()\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:24:50 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala"
        },
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508419761537_1816561636",
      "id": "20161011-151030_1991021842",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 24, 2017 10:22:23 AM",
      "dateFinished": "Oct 24, 2017 10:22:26 AM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Cuenta personas por edad\ndf.groupBy(\"age\").count().show()\n\ndf.groupBy(\"age\").count().explain(true)\n\n// Convierte a Dataset denotando el tipo\nval ds \u003d df.as[(Long,String)]\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:24:25 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala"
        },
        "editorHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508851404577_177942975",
      "id": "20171024-102324_940444908",
      "dateCreated": "Oct 24, 2017 10:23:24 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Ventajas/desventajas de las diferentes APIs",
      "user": "anonymous",
      "dateUpdated": "Oct 23, 2017 9:23:26 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eVentajas/desventajas de las diferentes APIs\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761550_1813098896",
      "id": "20161017-123303_1620980443",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 23, 2017 9:23:18 PM",
      "dateFinished": "Oct 23, 2017 9:23:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "APIs tipadas y no tipadas",
      "text": "print(s\"\"\"\n%table\nLenguaje\\t Abstracción Principal\nScala \\t Dataset[T] y Dataframe (Datset[Row])\nJava  \\t Dataset[T]\nPython \\t Dataframe\nR \\t Dataframe\n\"\"\")\n",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Lenguaje\t Abstracción Principal\nScala \t Dataset[T] y Dataframe (Datset[Row])\nJava  \t Dataset[T]\nPython \t Dataframe\nR \t Dataframe\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761551_1812714147",
      "id": "20161017-123522_72698600",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Detección de errores",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://cs.famaf.unc.edu.ar/~damian/bigdata/curso/posgrado_optativa/lectivo/presentaciones/08_datasets_dataframes/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761553_1822717618",
      "id": "20161017-124430_789707578",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Cuando usar Datasets Dataframes o RDD",
      "text": "%md\n* Si se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\n    - para desarrollar aplicaciones finales (Data Ingeeniering) usar **Datasets**.\n    - para análisis interactivo (Data Scientist) usar **Dataframes**. \n* Si se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar **Datasets**.\n* Si se quiere una API unificada a traves de la la librerías Spark usar **DataFrames** o **Datasets**.\n* Si se quiere trabajar en R no queda otra que usar **DataFrames**.\n* Si se quiere trabajar en Python no queda otra que usar **DataFrames** y recurrir a **RDDs** si se necesita mayor control.\n",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cul\u003e\n\u003cli\u003eSi se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\u003cul\u003e\n\u003cli\u003epara desarrollar aplicaciones finales (Data Ingeeniering) usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003epara análisis interactivo (Data Scientist) usar \u003cstrong\u003eDataframes\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSi se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere una API unificada a traves de la la librerías Spark usar \u003cstrong\u003eDataFrames\u003c/strong\u003e o \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en R no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en Python no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e y recurrir a \u003cstrong\u003eRDDs\u003c/strong\u003e si se necesita mayor control.\u003c/li\u003e\n\u003c/ul\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761554_1823871865",
      "id": "20161017-124933_322133526",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nCon el mismo dataset calcule la cantidad de registraciones por día de la semana.\n\n#### Ayuda:\n\nEn [SQL API Function Reference](http://spark.apache.org/docs/2.1.1/api/scala/index.html#org.apache.spark.sql.functions$) en la sección \"Date time functions\" hay métodos para manipular fechas.\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:26:08 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": false,
        "results": {},
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "tableHide": false,
        "title": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCon el mismo dataset calcule la cantidad de registraciones por día de la semana.\u003c/p\u003e\n\u003ch4\u003eAyuda:\u003c/h4\u003e\n\u003cp\u003eEn \u003ca href\u003d\"http://spark.apache.org/docs/2.1.1/api/scala/index.html#org.apache.spark.sql.functions$\"\u003eSQL API Function Reference\u003c/a\u003e en la sección \u0026ldquo;Date time functions\u0026rdquo; hay métodos para manipular fechas.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508793643665_-483149986",
      "id": "20171023-182043_62941752",
      "dateCreated": "Oct 23, 2017 6:20:43 PM",
      "dateStarted": "Oct 24, 2017 10:25:35 AM",
      "dateFinished": "Oct 24, 2017 10:25:37 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "\n",
      "user": "anonymous",
      "dateUpdated": "Oct 24, 2017 10:26:23 AM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508851570420_64688881",
      "id": "20171024-102610_1966830072",
      "dateCreated": "Oct 24, 2017 10:26:10 AM",
      "status": "READY",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Fin",
      "text": "val baseDir\u003d\"https://bytebucket.org/bigdata_famaf/curso_vates/raw/HEAD/clases\"\nz.put(\"baseDir\", baseDir)\nprint(\"\"\"%html\n\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "Oct 19, 2017 10:42:00 AM",
      "config": {
        "colWidth": 12.0,
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala",
        "tableHide": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "baseDir: String \u003d https://bytebucket.org/bigdata_famaf/curso_vates/raw/HEAD/clases\n"
          },
          {
            "type": "HTML",
            "data": "\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1508419761556_1821563372",
      "id": "20161011-125733_1279366716",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "dateStarted": "Oct 19, 2017 10:42:00 AM",
      "dateFinished": "Oct 19, 2017 10:42:01 AM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "dateUpdated": "Oct 19, 2017 10:29:21 AM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1508419761558_1822332870",
      "id": "20161011-131205_59629538",
      "dateCreated": "Oct 19, 2017 10:29:21 AM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Clase 03 - SQL",
  "id": "2CW8R6X8H",
  "angularObjects": {
    "2CU68GG2T:shared_process": [],
    "2CVS7262B:shared_process": [],
    "2CVRPE6UU:shared_process": [],
    "2CTT1QYY4:shared_process": [],
    "2CU5AU361:shared_process": [],
    "2CTT6BV2A:shared_process": [],
    "2CTEY6NNX:shared_process": [],
    "2CTQZEXVV:shared_process": [],
    "2CWGC7XHC:shared_process": [],
    "2CU7MZATZ:shared_process": [],
    "2CV2DAAF4:shared_process": [],
    "2CUZ7QHXW:shared_process": [],
    "2CWKV4BU5:shared_process": [],
    "2CTEAQKGK:shared_process": [],
    "2CW7DKJPA:shared_process": [],
    "2CVA1M5RT:shared_process": [],
    "2CT3EKZSX:shared_process": [],
    "2CTVFSDYS:shared_process": [],
    "2CW7VCDNZ:shared_process": []
  },
  "config": {},
  "info": {}
}