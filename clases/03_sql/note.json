{
  "paragraphs": [
    {
      "text": "print(s\"\"\"%html\n\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"$baseDir/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:12:01 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003ccenter\u003e\n    \u003ch1\u003e\u003ca href\u003d\"http://diplodatos.famaf.unc.edu.ar/\"\u003eDiplomatura en Ciencia de Datos, Aprendizaje Automático y sus Aplicaciones\u003c/a\u003e\u003c/h1\u003e\n    \u003ch2\u003eCurso \u003ca href\u003d\"https://sites.google.com/view/eleccion-optativas-diplodatos/programaci%C3%B3n-distribu%C3%ADda-sobre-grandes-vol%C3%BAmenes-de-datos\"\u003eProgramación Distribuida sobre Grandes Volúmenes de Datos\u003c/a\u003e\u003c/h2\u003e\n\u003c/center\u003e\n\n\u003cbr\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e Damián Barsotti  \u003c/h3\u003e\n\n\u003ch3 style\u003d\"text-align:center;\"\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    Facultad de Matemática Astronomía Física y Computación\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ca href\u003d\"http://www.unc.edu.ar\"\u003e\n    Universidad Nacional de Córdoba\n    \u003c/a\u003e\n\u003cbr/\u003e\n    \u003ccenter\u003e\n    \u003ca href\u003d\"http://www.famaf.unc.edu.ar\"\u003e\n    \u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/comun/logo%20UNC%20FAMAF%202016.png\" alt\u003d\"Drawing\" style\u003d\"width:50%;\"/\u003e\n    \u003c/a\u003e\n    \u003c/center\u003e\n\u003c/h3\u003e\n\n\u003cp style\u003d\"font-size:15px;\"\u003e\n    \u003cbr /\u003e\n        This work is licensed under a\n        \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003eCreative Commons Attribution-NonCommercial-ShareAlike 4.0 International License\u003c/a\u003e.\n    \u003ca rel\u003d\"license\" href\u003d\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"\u003e\n        \u003cimg alt\u003d\"Creative Commons License\" style\u003d\"border-width:0;vertical-align:middle;float:right\" src\u003d\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /\u003e\n    \u003c/a\u003e\n\u003c/p\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768599_427647766",
      "id": "20161011-125025_834797080",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:11:35 PM",
      "dateFinished": "Oct 11, 2018 7:11:36 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "",
      "text": "%md\n### Antes de comenzar\n#### En máquina virtual\n1. Lanzar terminal\n1. Actualizar repo:\n```sh\ncd diplodatos_bigdata\ngit pull\n```\n1. Lanzar [Zeppelin](http://zeppelin.apache.org/):\n```sh\ncd\ncd spark/zeppelin-0.7.3-bin-all\n./bin/zeppelin-daemon.sh start\n```\n1. En navegador abrir [http://localhost:8080](http://localhost:8080)\n1. Seleccionar `Import note`\n1. Elegir json en `diplodatos_bigdata/clases/03_sql/note.json`\n2. Seleccionar `Clase 03 - SQL`\n\n \n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:13:14 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": false,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eAntes de comenzar\u003c/h3\u003e\n\u003ch4\u003eEn máquina virtual\u003c/h4\u003e\n\u003col\u003e\n  \u003cli\u003eLanzar terminal\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eActualizar repo:\u003c/p\u003e\n  \u003cpre\u003e\u003ccode class\u003d\"sh\"\u003ecd diplodatos_bigdata\ngit pull\n\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n  \u003cli\u003e\n  \u003cp\u003eLanzar \u003ca href\u003d\"http://zeppelin.apache.org/\"\u003eZeppelin\u003c/a\u003e:\u003c/p\u003e\n  \u003cpre\u003e\u003ccode class\u003d\"sh\"\u003ecd\ncd spark/zeppelin-0.7.3-bin-all\n./bin/zeppelin-daemon.sh start\n\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n  \u003cli\u003eEn navegador abrir \u003ca href\u003d\"http://localhost:8080\"\u003ehttp://localhost:8080\u003c/a\u003e\u003c/li\u003e\n  \u003cli\u003eSeleccionar \u003ccode\u003eImport note\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eElegir json en \u003ccode\u003ediplodatos_bigdata/clases/03_sql/note.json\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003eSeleccionar \u003ccode\u003eClase 03 - SQL\u003c/code\u003e\u003c/li\u003e\n\u003c/ol\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768600_425724022",
      "id": "20171024-161854_528178880",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:13:01 PM",
      "dateFinished": "Oct 11, 2018 7:13:01 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n# Datasets/Dataframes\n\n* Spark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente **Spark SQL**.\n* Sus interfaces son **SQL** y **Dataset/Dataframe** API (programática, parecida a [Python Panda dataframes](http://pandas.pydata.org/pandas-docs/stable/dsintro.html)).\n\u003cbr\u003e\n\n    ```scala\n      type DataFrame \u003d Dataset[Row]\n    ```\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:43:07 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch1\u003eDatasets/Dataframes\u003c/h1\u003e\n\u003cul\u003e\n  \u003cli\u003eSpark permite interactuar con datos estructurados (Bases de Datos tabulares) o semiestructurados (JSON) con su componente \u003cstrong\u003eSpark SQL\u003c/strong\u003e.\u003c/li\u003e\n  \u003cli\u003eSus interfaces son \u003cstrong\u003eSQL\u003c/strong\u003e y \u003cstrong\u003eDataset/Dataframe\u003c/strong\u003e API (programática, parecida a \u003ca href\u003d\"http://pandas.pydata.org/pandas-docs/stable/dsintro.html\"\u003ePython Panda dataframes\u003c/a\u003e).\u003cbr/\u003e\u003cbr\u003e\n    \u003cpre\u003e\u003ccode class\u003d\"scala\"\u003e  type DataFrame \u003d Dataset[Row]\n\u003c/code\u003e\u003c/pre\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768600_425724022",
      "id": "20161011-125142_1705237118",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:43:00 PM",
      "dateFinished": "Oct 11, 2018 7:43:00 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:13:49 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/unified_stack.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768600_425724022",
      "id": "20161011-132101_236091967",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:13:38 PM",
      "dateFinished": "Oct 11, 2018 7:13:39 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "API 2.x.x unificada",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:14:53 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/dataset_dataframe_unificado.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768600_425724022",
      "id": "20161011-134614_1124280099",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:13:58 PM",
      "dateFinished": "Oct 11, 2018 7:13:58 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### SparkSession\n\n* Para acceder al cluster desde la API se utiliza `SparkSession`.\n* El `SparkContext` deriva de él.\n\n```scala\nimport org.apache.spark.sql.SparkSession\n\nval spark \u003d SparkSession\n  .builder()\n  .appName(\"Spark ejemplo\")\n  .config(\"spark.some.config.option\", \"algun-valor\")\n  .getOrCreate()\n\nval sc \u003d spark.sparkContext\n\n// Para conversion implícita, por ej entre RDD a DataFrames\nimport spark.implicits._\n```\n\n* En Zeppelin ya están predefinidos: \n  - `SparkSession` objeto `spark` \n  - `SparkContext` objeto `sc`\n\n(más información en [How to use SparkSession in Apache Spark 2.0](https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html))\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:20:05 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eSparkSession\u003c/h3\u003e\n\u003cul\u003e\n  \u003cli\u003ePara acceder al cluster desde la API se utiliza \u003ccode\u003eSparkSession\u003c/code\u003e.\u003c/li\u003e\n  \u003cli\u003eEl \u003ccode\u003eSparkContext\u003c/code\u003e deriva de él.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eimport org.apache.spark.sql.SparkSession\n\nval spark \u003d SparkSession\n  .builder()\n  .appName(\u0026quot;Spark ejemplo\u0026quot;)\n  .config(\u0026quot;spark.some.config.option\u0026quot;, \u0026quot;algun-valor\u0026quot;)\n  .getOrCreate()\n\nval sc \u003d spark.sparkContext\n\n// Para conversion implícita, por ej entre RDD a DataFrames\nimport spark.implicits._\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n  \u003cli\u003eEn Zeppelin ya están predefinidos:\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkSession\u003c/code\u003e objeto \u003ccode\u003espark\u003c/code\u003e\u003c/li\u003e\n  \u003cli\u003e\u003ccode\u003eSparkContext\u003c/code\u003e objeto \u003ccode\u003esc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e(más información en \u003ca href\u003d\"https://databricks.com/blog/2016/08/15/how-to-use-sparksession-in-apache-spark-2-0.html\"\u003eHow to use SparkSession in Apache Spark 2.0\u003c/a\u003e)\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768601_425339273",
      "id": "20161011-174856_51715674",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:19:49 PM",
      "dateFinished": "Oct 11, 2018 7:19:49 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Lectura de datos\n\n#### Estructurados y semiestructurados\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:21:29 PM",
      "config": {
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eLectura de datos\u003c/h3\u003e\n\u003ch4\u003eEstructurados y semiestructurados\u003c/h4\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768601_425339273",
      "id": "20171020-102828_1480663464",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:21:23 PM",
      "dateFinished": "Oct 11, 2018 7:21:23 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n\n#### Formatos:\n\n* json\n* csv\n* parquet\n* orc\n* libsvm\n* text\n* ...\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFormatos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003ejson\u003c/li\u003e\n  \u003cli\u003ecsv\u003c/li\u003e\n  \u003cli\u003eparquet\u003c/li\u003e\n  \u003cli\u003eorc\u003c/li\u003e\n  \u003cli\u003elibsvm\u003c/li\u003e\n  \u003cli\u003etext\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768601_425339273",
      "id": "20171019-163121_1592075078",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n#### Fuentes de datos:\n\n* Archivos en fs local o distribuid (ej hdfs)\n* jdbc (posgress, oracle, mysql,...)\n* Apache Hive (se usa execution backend Spark en ves de MR)\n* Amazon Redshift, S3\n* Azure Storage Services\n* Cassandra\n* MongoDB\n* Neo4j\n* ...",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch4\u003eFuentes de datos:\u003c/h4\u003e\n\u003cul\u003e\n  \u003cli\u003eArchivos en fs local o distribuid (ej hdfs)\u003c/li\u003e\n  \u003cli\u003ejdbc (posgress, oracle, mysql,\u0026hellip;)\u003c/li\u003e\n  \u003cli\u003eApache Hive (se usa execution backend Spark en ves de MR)\u003c/li\u003e\n  \u003cli\u003eAmazon Redshift, S3\u003c/li\u003e\n  \u003cli\u003eAzure Storage Services\u003c/li\u003e\n  \u003cli\u003eCassandra\u003c/li\u003e\n  \u003cli\u003eMongoDB\u003c/li\u003e\n  \u003cli\u003eNeo4j\u003c/li\u003e\n  \u003cli\u003e\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768602_426493519",
      "id": "20171020-102923_1888981134",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Ejemplo\n\n#### Tabla de perfiles [last.fm](last.fm)\n\nFormato:\n\n    id \\t gender (\u0027m\u0027|\u0027f\u0027|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEjemplo\u003c/h3\u003e\n\u003ch4\u003eTabla de perfiles \u003ca href\u003d\"last.fm\"\u003elast.fm\u003c/a\u003e\u003c/h4\u003e\n\u003cp\u003eFormato:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eid \\t gender (\u0026#39;m\u0026#39;|\u0026#39;f\u0026#39;|empty) \\t age (int|empty) \\t country (str|empty) \\t registered (date|empty)\n\u003c/code\u003e\u003c/pre\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768602_426493519",
      "id": "20171020-170028_1956391103",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nhead ../../diplodatos_bigdata/ds/userid-profile.tsv\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:26:27 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false
        },
        "editorMode": "ace/mode/sh"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539296771333_-829121098",
      "id": "20181011-192611_2092112872",
      "dateCreated": "Oct 11, 2018 7:26:11 PM",
      "dateStarted": "Oct 11, 2018 7:26:27 PM",
      "dateFinished": "Oct 11, 2018 7:26:28 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura",
      "text": "val profiles \u003d spark.read.format(\"csv\")\n                .option(\"delimiter\", \"\\\\t\")\n                .option(\"header\", \"true\")\n                .option(\"inferSchema\", \"true\")\n                .load(\"../../diplodatos_bigdata/ds/userid-profile.tsv\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:33:15 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768602_426493519",
      "id": "20171019-160931_1102056402",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:33:15 PM",
      "dateFinished": "Oct 11, 2018 9:33:16 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Esquema",
      "text": "profiles.printSchema\n\nprofiles.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:25:38 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768602_426493519",
      "id": "20171020-165528_926197483",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:25:38 PM",
      "dateFinished": "Oct 11, 2018 7:25:40 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Query SQL plano",
      "text": "profiles.createOrReplaceTempView(\"users\")\n\n//Cantidad de usuarios por país\nval nUsr4Ctry \u003d spark.sql(\"SELECT country, count(*) AS cantidad FROM users GROUP BY country ORDER BY cantidad DESC\")\n\nnUsr4Ctry.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:41:34 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768603_426108771",
      "id": "20171020-195004_405222821",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:41:35 PM",
      "dateFinished": "Oct 11, 2018 8:42:03 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Query SQL programático",
      "text": "val nUsr4Ctry2 \u003d profiles\n                .groupBy($\"country\").agg(count($\"*\").as(\"cantidad\"))\n                .orderBy($\"cantidad\".desc)\n// Cada operación SQL también es un método\n\nnUsr4Ctry2.show\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:41:36 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768603_426108771",
      "id": "20171020-181216_461915575",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:41:58 PM",
      "dateFinished": "Oct 11, 2018 8:42:06 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nComplete el código siguiente para calcular en un Dataframe la cantidad de usuarios por pais desagregando por sexo usando SQL plano o programático.",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:50:18 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eComplete el código siguiente para calcular en un Dataframe la cantidad de usuarios por pais desagregando por sexo usando SQL plano o programático.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768603_426108771",
      "id": "20171023-114452_748688701",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:50:18 PM",
      "dateFinished": "Oct 11, 2018 7:50:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Con SQL plano\n\nval nUsr4CtryGen \u003d spark.sql(\"SELECT country, gender, count(*) AS cantidad FROM users GROUP BY ... ORDER BY ...\")\n\nnUsr4CtryGen.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:53:16 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768603_426108771",
      "id": "20171024-102640_808955464",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:50:43 PM",
      "dateFinished": "Oct 11, 2018 7:50:44 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Con SQL porgramático\n\nval nUsr4CtryGen2 \u003d profiles\n                .groupBy($\"country\", ...).agg(count($\"*\").as(\"cantidad\"))\n                .orderBy($\"country\", ...)\n\nnUsr4CtryGen2.show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:54:29 PM",
      "config": {
        "colWidth": 12.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539298280964_-1501653429",
      "id": "20181011-195120_1975378038",
      "dateCreated": "Oct 11, 2018 7:51:20 PM",
      "dateStarted": "Oct 11, 2018 7:53:38 PM",
      "dateFinished": "Oct 11, 2018 7:53:40 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura desde JDBC",
      "text": "%md\n```scala\nval opts \u003d Map(\n  \"url\" -\u003e \"jdbc:postgresql:sparkdb\",\n  \"dbtable\" -\u003e \"projects\")\nval df \u003d spark.\n  read.\n  format(\"jdbc\").\n  options(opts).\n  load\n```\nMás información en:\n\n* [Mastering Apache Spark](https://jaceklaskowski.gitbooks.io/mastering-apache-spark/exercises/spark-exercise-dataframe-jdbc-postgresql.html).\n* [Databricks](https://docs.databricks.com/spark/latest/data-sources/sql-databases.html).\n\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eval opts \u003d Map(\n  \u0026quot;url\u0026quot; -\u0026gt; \u0026quot;jdbc:postgresql:sparkdb\u0026quot;,\n  \u0026quot;dbtable\u0026quot; -\u0026gt; \u0026quot;projects\u0026quot;)\nval df \u003d spark.\n  read.\n  format(\u0026quot;jdbc\u0026quot;).\n  options(opts).\n  load\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://jaceklaskowski.gitbooks.io/mastering-apache-spark/exercises/spark-exercise-dataframe-jdbc-postgresql.html\"\u003eMastering Apache Spark\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://docs.databricks.com/spark/latest/data-sources/sql-databases.html\"\u003eDatabricks\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768604_424185026",
      "id": "20171023-092655_178501000",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Lectura desde HIVE",
      "text": "%md\n```scala\nval spark \u003d SparkSession\n  .builder()\n  .appName(\"Spark Hive Example\")\n  .config(\"spark.sql.warehouse.dir\", warehouseLocation)\n  .enableHiveSupport()\n  .getOrCreate()\n  \nval sqlDF \u003d spark.sql(\"SELECT key, value FROM src WHERE key \u003c 10 ORDER BY key\")\n```\nMás información en:\n\n* [Spark SQL](https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables).\n* [Mastering Spark](https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-hive-integration.html).\n\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:41:30 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cpre\u003e\u003ccode class\u003d\"scala\"\u003eval spark \u003d SparkSession\n  .builder()\n  .appName(\u0026quot;Spark Hive Example\u0026quot;)\n  .config(\u0026quot;spark.sql.warehouse.dir\u0026quot;, warehouseLocation)\n  .enableHiveSupport()\n  .getOrCreate()\n  \nval sqlDF \u003d spark.sql(\u0026quot;SELECT key, value FROM src WHERE key \u0026lt; 10 ORDER BY key\u0026quot;)\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eMás información en:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://spark.apache.org/docs/latest/sql-programming-guide.html#hive-tables\"\u003eSpark SQL\u003c/a\u003e.\u003c/li\u003e\n  \u003cli\u003e\u003ca href\u003d\"https://jaceklaskowski.gitbooks.io/mastering-spark-sql/spark-sql-hive-integration.html\"\u003eMastering Spark\u003c/a\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768604_424185026",
      "id": "20171023-093701_2112740736",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:41:19 PM",
      "dateFinished": "Oct 11, 2018 7:41:19 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Escritura",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEscritura\u003c/h3\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768604_424185026",
      "id": "20171023-115539_2069683705",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "SQL",
      "text": "spark.sql(\"drop table if exists mytable\") // borro la tabla si existe\n\nspark.sql(\"create table mytable as select * from users\");\n// Simula Hive Dat Warehouse local\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:09:38 PM",
      "config": {
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768604_424185026",
      "id": "20171023-115517_1163412651",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:09:38 PM",
      "dateFinished": "Oct 11, 2018 8:09:39 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Dataframe",
      "text": "import org.apache.spark.sql.SaveMode\n\nprofiles.write.mode(SaveMode.Overwrite).save(\"./profiles.parquet\")\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:44:02 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768605_423800277",
      "id": "20171023-115718_1445962443",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:44:02 PM",
      "dateFinished": "Oct 11, 2018 7:44:03 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%sh\nls -ld ./spark-warehouse\nls -l ./spark-warehouse\n\nls -ld ./*.parquet",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:44:06 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/sh",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "sh",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768605_423800277",
      "id": "20171023-165238_672281439",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 7:44:07 PM",
      "dateFinished": "Oct 11, 2018 7:44:07 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nComplete el siguiente programa par calcular la edad promedio por género y guarde el resultado como tabla SQL y como archivo parquet.\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:15:54 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eComplete el siguiente programa par calcular la edad promedio por género y guarde el resultado como tabla SQL y como archivo parquet.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768605_423800277",
      "id": "20171023-164954_326955331",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:11:16 PM",
      "dateFinished": "Oct 11, 2018 8:11:16 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Como tabla SQL\n\nspark.sql(\"drop table if exists gen_prom\") // borro la tabla si existe\n\nspark.sql(\"create table gen_prom as SELECT gender, avg(...) AS age_avg FROM users GROUP BY ...\")\n\n// Cargo tabla y muestro su contenido\nspark.sql(\"select * from gen_prom\").show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:18:04 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "results": {},
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768605_423800277",
      "id": "20171024-102625_2088080876",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:09:04 PM",
      "dateFinished": "Oct 11, 2018 8:09:10 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Como parquet\n\nval genProm \u003d profiles\n                .groupBy($\"...\").agg(avg($\"...\").as(\"age_avg\"))\n\nimport org.apache.spark.sql.SaveMode\n\ngenProm.write.mode(SaveMode.Overwrite).save(\"./gen_prom.parquet\")\n\n// Cargo parquet y muestro su contenido\nspark.read.load(\"./gen_prom.parquet\").show\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:45:40 PM",
      "config": {
        "colWidth": 6.0,
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539299550409_382472849",
      "id": "20181011-201230_108637768",
      "dateCreated": "Oct 11, 2018 8:12:30 PM",
      "dateStarted": "Oct 11, 2018 8:44:28 PM",
      "dateFinished": "Oct 11, 2018 8:44:34 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\nMas información en \n* [API Dataset](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset)\n* [Column Class](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column)\n* [Function Reference](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$)\n* [Doc Spark SQL](http://spark.apache.org/docs/latest/sql-programming-guide.html)\n* [API DataFrameWriter](http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameWriter)",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eMas información en\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Dataset\"\u003eAPI Dataset\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.Column\"\u003eColumn Class\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.functions$\"\u003eFunction Reference\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/sql-programming-guide.html\"\u003eDoc Spark SQL\u003c/a\u003e\u003cbr/\u003e* \u003ca href\u003d\"http://spark.apache.org/docs/latest/api/scala/index.html#org.apache.spark.sql.DataFrameWriter\"\u003eAPI DataFrameWriter\u003c/a\u003e\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768605_423800277",
      "id": "20161012-103356_1938807399",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n### Eficiencia\n\nLos **RDD** tienen el overhead de la *serialización* (aunque use *Kryo*):\n\n* cuando los objetos se transfieren (por red) y guardan (disco)\n* overhead de garbage collector de la JVM\n\nLos **Datasets** solucionan estos problemas:\n\n* Serializa a binario usando **encoders**\n    - parte del proyecto Tungsten\n    - permite operaciones sin deserializar\n    - corre *off-heap* (sin garbage collection)\n    - código para serialización generado en forma dinámica\n* Con la información de la estructura (*schema*) Spark hace optimizaciones.\n    - Usa *Catalyst optimizer*.\n    - Transfiere solo columnas usadas, no objetos enteros (relational query plan).\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 8:26:43 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch3\u003eEficiencia\u003c/h3\u003e\n\u003cp\u003eLos \u003cstrong\u003eRDD\u003c/strong\u003e tienen el overhead de la \u003cem\u003eserialización\u003c/em\u003e (aunque use \u003cem\u003eKryo\u003c/em\u003e):\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003ecuando los objetos se transfieren (por red) y guardan (disco)\u003c/li\u003e\n  \u003cli\u003eoverhead de garbage collector de la JVM\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eLos \u003cstrong\u003eDatasets\u003c/strong\u003e solucionan estos problemas:\u003c/p\u003e\n\u003cul\u003e\n  \u003cli\u003eSerializa a binario usando \u003cstrong\u003eencoders\u003c/strong\u003e\n    \u003cul\u003e\n      \u003cli\u003eparte del proyecto Tungsten\u003c/li\u003e\n      \u003cli\u003epermite operaciones sin deserializar\u003c/li\u003e\n      \u003cli\u003ecorre \u003cem\u003eoff-heap\u003c/em\u003e (sin garbage collection)\u003c/li\u003e\n      \u003cli\u003ecódigo para serialización generado en forma dinámica\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n  \u003cli\u003eCon la información de la estructura (*schema*) Spark hace optimizaciones.\n    \u003cul\u003e\n      \u003cli\u003eUsa \u003cem\u003eCatalyst optimizer\u003c/em\u003e.\u003c/li\u003e\n      \u003cli\u003eTransfiere solo columnas usadas, no objetos enteros (relational query plan).\u003c/li\u003e\n    \u003c/ul\u003e\n  \u003c/li\u003e\n\u003c/ul\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768606_424954524",
      "id": "20161011-174737_215333010",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 8:26:43 PM",
      "dateFinished": "Oct 11, 2018 8:26:43 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "WordCount con RDD",
      "text": "val linesRDD \u003d sc.textFile(\"README.md\")\n\nval wordsRDD \u003d linesRDD\n                .flatMap(l \u003d\u003e l.split(\" \"))\n                .filter(w \u003d\u003e ! w.isEmpty)\n//MapReduce:\nval wordCountRDD \u003d wordsRDD.map(w \u003d\u003e (w,1))\n                .reduceByKey((nx,ny) \u003d\u003e nx+ny)\n\nval resultRDD \u003d wordCountRDD\n                .sortBy((p \u003d\u003e p._2), ascending \u003d false)\n                // ordena por cantidad\n\nprintln(\"Resultado:\")\n\nresultRDD.collect() // traigo resultados\n      .take(3)\n      .foreach(p \u003d\u003e println(p))",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768606_424954524",
      "id": "20161011-173655_294413553",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "WordCount con Dataset",
      "text": "val linesDS \u003d spark.read.text(\"README.md\").as[String]\n\nval wordsDS \u003d linesDS\n                .flatMap(l \u003d\u003e l.split(\" \"))\n                .filter(w \u003d\u003e ! w.isEmpty)\n\nval wordCountDS \u003d wordsDS\n                .groupBy($\"value\").count\n\nval resultDS \u003d wordCountDS\n                .orderBy($\"count\".desc)\n                // ordena por cantidad\n\nprintln(\"Resultado:\")\n\nresultDS.show(3)\n\nprintln(\"El schema de words es:\")\nwordsDS.printSchema()",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "lineNumbers": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768606_424954524",
      "id": "20161011-190925_989390669",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:20:01 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/Distributed-Wordcount-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768606_424954524",
      "id": "20161011-201107_202795512",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:19:18 PM",
      "dateFinished": "Oct 11, 2018 9:19:18 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:19:52 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/Memory-Usage-when-Caching-Chart.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768607_424569775",
      "id": "20161011-201419_1048673058",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:19:36 PM",
      "dateFinished": "Oct 11, 2018 9:19:37 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Tungsten en acción",
      "text": "val ints \u003d 1 to math.pow(10, 6).toInt\nval intsRDD \u003d sc.parallelize(ints).setName(\"intsRDD\").cache\n\n// Fuerzo evaluacion\nintsRDD.count\n\n// Ver sparkui storage. Descomentar proximas lineas y ver de nuevo\n\n//val intsDF \u003d ints.toDF.cache\n\n//intsDF.count\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:22:22 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "title": true,
        "results": {},
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768607_424569775",
      "id": "20161017-104100_1861019655",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:21:24 PM",
      "dateFinished": "Oct 11, 2018 9:21:42 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "{\nval uiHost \u003d sc.getConf.getOption(\"spark.driver.host\").getOrElse(\"localhost\")\nval uiPort \u003d sc.getConf.getOption(\"spark.ui.port\").getOrElse(\"4040\")\nprint(s\"\"\"\n%html\n\u003cbr\u003e\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://$uiHost:$uiPort/storage\"\u003ehttp://$uiHost(host):$uiPort(port)/storage\u003c/a\u003e\n\"\"\")\n}",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:22:37 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true,
        "tableHide": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "\n"
          },
          {
            "type": "HTML",
            "data": "\u003cbr\u003e\nVer resultado en Spark UI Storage\n\u003ca href\u003d\"http://192.168.1.201:4040/storage\"\u003ehttp://192.168.1.201(host):4040(port)/storage\u003c/a\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768607_424569775",
      "id": "20161017-104452_771251326",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:20:49 PM",
      "dateFinished": "Oct 11, 2018 9:20:50 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejemplo",
      "text": "val df \u003d spark.read.json(\"../../diplodatos_bigdata/ds/people.json\")\n\n// Displays the content of the DataFrame to stdout\ndf.show()\n\n// Selecciona todo incrementando la edad\ndf.select($\"name\", $\"age\" + 1).show()\n\n// Selecciona personas con mas de 21 años\ndf.filter($\"age\" \u003e 21).show()\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:28:17 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768607_424569775",
      "id": "20161011-151030_1991021842",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:28:18 PM",
      "dateFinished": "Oct 11, 2018 9:28:20 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "// Cuenta personas por edad\ndf.groupBy(\"age\").count().show()\n\ndf.groupBy(\"age\").count().explain(true)\n\n// Convierte a Dataset denotando el tipo\nval ds \u003d df.as[(Long,String)]\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": false,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768608_410334066",
      "id": "20171024-102324_940444908",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "%md\n## Ventajas/desventajas de las diferentes APIs",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003ch2\u003eVentajas/desventajas de las diferentes APIs\u003c/h2\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768608_410334066",
      "id": "20161017-123303_1620980443",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "APIs tipadas y no tipadas",
      "text": "print(s\"\"\"\n%table\nLenguaje\\t Abstracción Principal\nScala \\t Dataset[T] y Dataframe (Datset[Row])\nJava  \\t Dataset[T]\nPython \\t Dataframe\nR \\t Dataframe\n\"\"\")\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [
                {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                }
              ],
              "values": [
                {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              ],
              "groups": [],
              "scatter": {
                "xAxis": {
                  "name": "Lenguaje",
                  "index": 0.0,
                  "aggr": "sum"
                },
                "yAxis": {
                  "name": " Abstracción Principal",
                  "index": 1.0,
                  "aggr": "sum"
                }
              }
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TABLE",
            "data": "Lenguaje\t Abstracción Principal\nScala \t Dataset[T] y Dataframe (Datset[Row])\nJava  \t Dataset[T]\nPython \t Dataframe\nR \t Dataframe\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768608_410334066",
      "id": "20161017-123522_72698600",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Detección de errores",
      "text": "print(s\"\"\"%html\n\u0026nbsp;\n\u003cimg src\u003d\"$baseDir/03_sql/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:27:44 PM",
      "config": {
        "colWidth": 6.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false,
        "editorSetting": {
          "language": "scala"
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u0026nbsp;\n\u003cimg src\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases/03_sql/type-safety-spectrum.png\" alt\u003d\"Drawing\" style\u003d\"width: 100%;\"/\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768609_409949317",
      "id": "20161017-124430_789707578",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:27:24 PM",
      "dateFinished": "Oct 11, 2018 9:27:25 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Cuando usar Datasets Dataframes o RDD",
      "text": "%md\n* Si se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\n    - para desarrollar aplicaciones finales (Data Ingeeniering) usar **Datasets**.\n    - para análisis interactivo (Data Scientist) usar **Dataframes**. \n* Si se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar **Datasets**.\n* Si se quiere una API unificada a traves de la la librerías Spark usar **DataFrames** o **Datasets**.\n* Si se quiere trabajar en R no queda otra que usar **DataFrames**.\n* Si se quiere trabajar en Python no queda otra que usar **DataFrames** y recurrir a **RDDs** si se necesita mayor control.\n",
      "dateUpdated": "Oct 11, 2018 7:09:28 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": false
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cul\u003e\n\u003cli\u003eSi se necesita expresiones de alto nivel, filters, maps, aggregations, promedios, sumatorias, queries SQL, acceso por columna y funciones lambda sobre datos semiestructurados\u003cul\u003e\n\u003cli\u003epara desarrollar aplicaciones finales (Data Ingeeniering) usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003epara análisis interactivo (Data Scientist) usar \u003cstrong\u003eDataframes\u003c/strong\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSi se necesita mayor seguridad de tipos chequeandolos a tiempo de compilación, objetos JVM, beneficios de optimización Catalyst y código eficiente con Tungsten usar \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere una API unificada a traves de la la librerías Spark usar \u003cstrong\u003eDataFrames\u003c/strong\u003e o \u003cstrong\u003eDatasets\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en R no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eSi se quiere trabajar en Python no queda otra que usar \u003cstrong\u003eDataFrames\u003c/strong\u003e y recurrir a \u003cstrong\u003eRDDs\u003c/strong\u003e si se necesita mayor control.\u003c/li\u003e\n\u003c/ul\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768609_409949317",
      "id": "20161017-124933_322133526",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "READY",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Ejercicio",
      "text": "%md\nCon el dataset `profiles` complete el siguiente código para calcular la cantidad de registraciones por día de la semana.\n\n#### Ayuda:\n\nEn [SQL API Function Reference](http://spark.apache.org/docs/2.1.1/api/scala/index.html#org.apache.spark.sql.functions$) en la sección \"Date time functions\" hay métodos para manipular fechas.\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:47:11 PM",
      "config": {
        "tableHide": false,
        "editorSetting": {
          "language": "markdown",
          "editOnDblClick": true
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/markdown",
        "editorHide": true,
        "title": true,
        "results": {},
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "HTML",
            "data": "\u003cdiv class\u003d\"markdown-body\"\u003e\n\u003cp\u003eCon el dataset \u003ccode\u003eprofiles\u003c/code\u003e complete el siguiente código para calcular la cantidad de registraciones por día de la semana.\u003c/p\u003e\n\u003ch4\u003eAyuda:\u003c/h4\u003e\n\u003cp\u003eEn \u003ca href\u003d\"http://spark.apache.org/docs/2.1.1/api/scala/index.html#org.apache.spark.sql.functions$\"\u003eSQL API Function Reference\u003c/a\u003e en la sección \u0026ldquo;Date time functions\u0026rdquo; hay métodos para manipular fechas.\u003c/p\u003e\n\u003c/div\u003e"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768609_409949317",
      "id": "20171023-182043_62941752",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:47:11 PM",
      "dateFinished": "Oct 11, 2018 9:47:11 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "val regByDayOfWeek \u003d profiles.select($\"registered\", unix_timestamp($\"registered\", ...).as(\"reg_sec\"))\n                    .select($\"*\", from_unixtime(...,\"E\").as(\"day_week\"))\n\n\nz.show(regByDayOfWeek.groupBy($\"day_week\").count)\n",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:46:37 PM",
      "config": {
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "results": {
          "1": {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false
            },
            "helium": {}
          }
        },
        "enabled": true,
        "editorSetting": {
          "language": "scala",
          "editOnDblClick": false
        }
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768610_411103563",
      "id": "20171024-102610_1966830072",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:45:10 PM",
      "dateFinished": "Oct 11, 2018 9:45:13 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    },
    {
      "title": "Fin",
      "text": "val baseDir\u003d\"https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\"\n\nz.put(\"baseDir\", baseDir)\nprint(\"\"\"%html\n\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n\"\"\")",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 9:48:51 PM",
      "config": {
        "tableHide": true,
        "editorSetting": {
          "language": "scala"
        },
        "colWidth": 12.0,
        "editorMode": "ace/mode/scala",
        "editorHide": true,
        "title": true,
        "results": [
          {
            "graph": {
              "mode": "table",
              "height": 300.0,
              "optionOpen": false,
              "keys": [],
              "values": [],
              "groups": [],
              "scatter": {}
            }
          }
        ],
        "enabled": true
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "results": {
        "code": "SUCCESS",
        "msg": [
          {
            "type": "TEXT",
            "data": "baseDir: String \u003d https://git.cs.famaf.unc.edu.ar/dbarsotti/diplodatos_bigdata/raw/master/clases\n"
          },
          {
            "type": "HTML",
            "data": "\u003cscript\u003e\n    var heads \u003d document.getElementsByTagName(\u0027h2\u0027);\n    var numHeads \u003d heads.length;\n    var inner \u003d \"\";\n    var i \u003d 0;\n    var j \u003d 0;\n    while (i \u003c numHeads){\n        inner \u003d heads[i].innerHTML;\n        if (inner.search(\".-\") !\u003d -1 ) {\n            j++;\n            heads[i].innerHTML \u003d inner.replace(/(~|\\d+)\\.-/,\"\"+j+\".-\");\n        }\n        i++\n    }\n\u003c/script\u003e\n"
          }
        ]
      },
      "apps": [],
      "jobName": "paragraph_1539295768610_411103563",
      "id": "20161011-125733_1279366716",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "dateStarted": "Oct 11, 2018 9:04:07 PM",
      "dateFinished": "Oct 11, 2018 9:04:08 PM",
      "status": "FINISHED",
      "progressUpdateIntervalMs": 500
    },
    {
      "text": "",
      "user": "anonymous",
      "dateUpdated": "Oct 11, 2018 7:11:06 PM",
      "config": {
        "colWidth": 12.0,
        "graph": {
          "mode": "table",
          "height": 300.0,
          "optionOpen": false,
          "keys": [],
          "values": [],
          "groups": [],
          "scatter": {}
        },
        "enabled": true,
        "results": {},
        "editorSetting": {
          "language": "scala"
        },
        "editorMode": "ace/mode/scala"
      },
      "settings": {
        "params": {},
        "forms": {}
      },
      "apps": [],
      "jobName": "paragraph_1539295768610_411103563",
      "id": "20161011-131205_59629538",
      "dateCreated": "Oct 11, 2018 7:09:28 PM",
      "status": "FINISHED",
      "errorMessage": "",
      "progressUpdateIntervalMs": 500
    }
  ],
  "name": "Clase 03 - SQL",
  "id": "2DUKJZ971",
  "angularObjects": {
    "2DVCPKERU:shared_process": [],
    "2DRH5MGD2:shared_process": [],
    "2DT8RGM5K:shared_process": [],
    "2DTBNGED4:shared_process": [],
    "2DUJTWGBK:shared_process": [],
    "2DVDPKT5E:shared_process": [],
    "2DTHT6XEM:shared_process": [],
    "2DSR5ZQRN:shared_process": [],
    "2DUUQHMED:shared_process": [],
    "2DUYR3928:shared_process": [],
    "2DU693TAM:shared_process": [],
    "2DTUS9FCK:shared_process": [],
    "2DSAF8SZS:shared_process": [],
    "2DSYWZ69A:shared_process": [],
    "2DTR3QF32:shared_process": [],
    "2DU2RAXU9:shared_process": [],
    "2DSG68MMD:shared_process": [],
    "2DTTN7EC4:shared_process": [],
    "2DV1379NW:shared_process": []
  },
  "config": {},
  "info": {}
}